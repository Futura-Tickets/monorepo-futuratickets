# üìã PASOS PARA CONFIGURAR GOOGLE CLOUD STORAGE

## ‚úÖ Ya Completado

1. ‚úÖ Desinstalado Azure Blob Storage
2. ‚úÖ Instalado Google Cloud Storage SDK (`@google-cloud/storage`)
3. ‚úÖ Creado servicio de Storage (`src/Storage/storage.service.ts`)
4. ‚úÖ Creado m√≥dulo de Storage (`src/Storage/storage.module.ts`)
5. ‚úÖ Creado interceptor de uploads (`src/Storage/storage.interceptor.ts`)
6. ‚úÖ Actualizado `event.module.ts` para usar GCS
7. ‚úÖ Actualizado `admin-event.controller.ts` con nuevo endpoint
8. ‚úÖ Actualizado validaci√≥n de variables de entorno
9. ‚úÖ Actualizado archivo `.env` con variables GCS

## üîß PASOS PENDIENTES (Para que funcione)

### Paso 1: Crear Proyecto en Google Cloud Platform

1. Ve a: https://console.cloud.google.com
2. Click en el selector de proyectos (arriba a la izquierda)
3. Click "NEW PROJECT"
4. Nombre del proyecto: `futuratickets-dev` (o el que prefieras)
5. Click "CREATE"
6. **Anota el Project ID** que aparece (puede ser diferente al nombre)

### Paso 2: Habilitar la API de Cloud Storage

1. En el men√∫ lateral, ve a **APIs & Services > Library**
2. Busca "Cloud Storage API"
3. Click en "Cloud Storage API"
4. Click "ENABLE"

### Paso 3: Crear un Bucket de Storage

Opci√≥n A - Desde la Consola Web:
1. En el men√∫ lateral, ve a **Cloud Storage > Buckets**
2. Click "CREATE BUCKET"
3. Configuraci√≥n:
   - **Name**: `futuratickets-dev-images` (debe ser √∫nico globalmente)
   - **Location type**: Region
   - **Location**: `europe-west1` (Madrid) o `us-central1` (USA)
   - **Storage class**: Standard
   - **Access control**: Uniform
   - **Public access**: "Prevent public access" por ahora
4. Click "CREATE"

Opci√≥n B - Desde gcloud CLI:
```bash
# Instalar gcloud CLI primero si no lo tienes
# https://cloud.google.com/sdk/docs/install

# Crear bucket
gcloud storage buckets create gs://futuratickets-dev-images \
  --project=TU_PROJECT_ID \
  --location=europe-west1 \
  --uniform-bucket-level-access
```

### Paso 4: Crear Service Account

1. En el men√∫ lateral, ve a **IAM & Admin > Service Accounts**
2. Click "CREATE SERVICE ACCOUNT"
3. Configuraci√≥n:
   - **Service account name**: `futuratickets-storage`
   - **Service account ID**: (se genera autom√°ticamente)
   - **Description**: `Service account para subir im√°genes a Cloud Storage`
4. Click "CREATE AND CONTINUE"
5. En "Grant this service account access to project":
   - Busca y selecciona el rol: **Storage Object Admin**
6. Click "CONTINUE"
7. Click "DONE"

### Paso 5: Crear y Descargar la Clave JSON

1. En la lista de Service Accounts, encuentra `futuratickets-storage`
2. Click en los tres puntos (‚ãÆ) a la derecha
3. Click "Manage keys"
4. Click "ADD KEY" > "Create new key"
5. Selecciona "JSON"
6. Click "CREATE"
7. Se descargar√° un archivo JSON (gu√°rdalo bien, ¬°no lo compartas!)

### Paso 6: Configurar la Clave en el Proyecto

1. Crea la carpeta `config` en la ra√≠z del proyecto:
```bash
mkdir -p config
```

2. Mueve el archivo JSON descargado a esta carpeta:
```bash
# Ejemplo si est√° en Downloads
mv ~/Downloads/futuratickets-dev-*.json ./config/gcs-service-account-key.json
```

3. **IMPORTANTE**: Aseg√∫rate de que `config/` est√© en `.gitignore`:
```bash
echo "config/" >> .gitignore
```

### Paso 7: Actualizar Variables de Entorno

Edita el archivo `.env` y reemplaza estos valores:

```bash
# Google Cloud Storage
GCS_PROJECT_ID=tu-project-id-real       # El Project ID de GCP
GCS_BUCKET_NAME=futuratickets-dev-images  # El nombre de tu bucket
GCS_KEY_FILE=./config/gcs-service-account-key.json  # Ruta al JSON
```

**Ejemplo real:**
```bash
GCS_PROJECT_ID=futuratickets-dev-123456
GCS_BUCKET_NAME=futuratickets-dev-images
GCS_KEY_FILE=./config/gcs-service-account-key.json
```

### Paso 8: Verificar la Configuraci√≥n

Ejecuta este comando para verificar que todo est√° bien:

```bash
npm run start:dev
```

Deber√≠as ver en los logs:
```
‚úÖ Environment variables validated successfully
[Nest] ... StorageService initialized
```

### Paso 9: Probar el Upload

Prueba subir una imagen usando curl:

```bash
# Primero necesitas obtener un JWT token de autenticaci√≥n
# (debes hacer login como promoter primero)

curl -X POST http://localhost:3004/admin/events/upload \
  -H "Authorization: Bearer TU_JWT_TOKEN" \
  -F "file=@ruta/a/tu/imagen.jpg"
```

Respuesta esperada:
```json
{
  "url": "https://storage.googleapis.com/futuratickets-dev-images/1234567890-abc123.jpg",
  "filename": "1234567890-abc123.jpg"
}
```

### Paso 10: (Opcional) Hacer el Bucket P√∫blico

Si quieres que las im√°genes sean accesibles sin autenticaci√≥n:

```bash
# Opci√≥n 1: gcloud CLI
gsutil iam ch allUsers:objectViewer gs://futuratickets-dev-images

# Opci√≥n 2: Desde la consola
# 1. Ve al bucket en Cloud Storage
# 2. Click en "PERMISSIONS"
# 3. Click "GRANT ACCESS"
# 4. Principal: allUsers
# 5. Role: Storage Object Viewer
# 6. Click "SAVE"
```

## üîç Verificar que Todo Funciona

### Checklist Final:

- [ ] Proyecto GCP creado
- [ ] API de Cloud Storage habilitada
- [ ] Bucket creado
- [ ] Service Account creado con rol "Storage Object Admin"
- [ ] Clave JSON descargada y guardada en `./config/`
- [ ] Variables de entorno actualizadas en `.env`
- [ ] Servidor arranca sin errores
- [ ] Endpoint `/admin/events/upload` responde correctamente
- [ ] Las im√°genes se suben al bucket

## üìä Estado Actual del C√≥digo

### Archivos Creados/Modificados:

```
src/Storage/
‚îú‚îÄ‚îÄ storage.service.ts         ‚úÖ Servicio GCS completo
‚îú‚îÄ‚îÄ storage.module.ts          ‚úÖ M√≥dulo NestJS
‚îî‚îÄ‚îÄ storage.interceptor.ts     ‚úÖ Interceptor para uploads

src/Event/
‚îú‚îÄ‚îÄ event.module.ts            ‚úÖ Actualizado (GCS en lugar de Azure)
‚îî‚îÄ‚îÄ admin-event.controller.ts  ‚úÖ Endpoint /upload actualizado

src/config/
‚îî‚îÄ‚îÄ env.validation.ts          ‚úÖ Validaci√≥n GCS

.env                           ‚úÖ Variables GCS configuradas (placeholder)

MIGRATION_AZURE_TO_GCS.md     ‚úÖ Gu√≠a completa de migraci√≥n
```

### Estructura del Servicio de Storage:

```typescript
// M√©todos disponibles en StorageService:

uploadFile(file, filename, contentType)
// Sube un archivo y devuelve la URL p√∫blica

deleteFile(filename)
// Elimina un archivo del bucket

getSignedUrl(filename, expiresIn)
// Genera una URL firmada temporal (para acceso privado)

fileExists(filename)
// Verifica si existe un archivo
```

## üö® Errores Comunes

### Error: "GCS_PROJECT_ID is required"
**Soluci√≥n**: Actualiza el `.env` con tu Project ID real

### Error: "Could not load the default credentials"
**Soluci√≥n**: Verifica que el archivo JSON existe en la ruta especificada en `GCS_KEY_FILE`

### Error: "Permission denied"
**Soluci√≥n**: Aseg√∫rate de que el Service Account tiene el rol "Storage Object Admin"

### Error: "Bucket does not exist"
**Soluci√≥n**: Verifica que el nombre del bucket en `GCS_BUCKET_NAME` coincide exactamente con el creado en GCP

### Error al subir: "File too large"
**Soluci√≥n**: Configura l√≠mites en Multer si necesitas archivos grandes:
```typescript
// En event.module.ts
MulterModule.register({
  limits: {
    fileSize: 10 * 1024 * 1024, // 10MB
  }
})
```

## üìû Soporte

Si tienes problemas:
1. Revisa los logs del servidor: `npm run start:dev`
2. Verifica que todas las variables de entorno est√°n correctas
3. Comprueba los permisos del Service Account en GCP
4. Consulta la documentaci√≥n completa en `MIGRATION_AZURE_TO_GCS.md`

## üéØ Pr√≥ximos Pasos Opcionales

Una vez que todo funcione:

1. **Migrar im√°genes existentes de Azure** (si las hay)
   - Ver script en `MIGRATION_AZURE_TO_GCS.md`

2. **Configurar CDN** para mejorar performance
   - Cloud CDN de Google Cloud

3. **Implementar compresi√≥n de im√°genes**
   - Sharp.js para optimizar antes de subir

4. **A√±adir validaci√≥n de tipos de archivo**
   - Solo permitir jpg, png, webp, etc.

5. **Implementar l√≠mites de tama√±o**
   - Validar tama√±o antes de upload
